{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53Ja9bq50OsN"
      },
      "source": [
        "# Now that Ive applied for industry jobs, I know how important it is to write code as presentable/reusable to link to my resume. \n",
        "- Not sure why I never used to think people would care about this.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# This file will contain the code for Image Fraud Detection via my modified YOLO-based method (including data preprocessing, pre-training, finetuning, etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6g3l3802P6o"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urfQyVomN920"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import re\n",
        "import yaml\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import glob\n",
        "import random\n",
        "import os\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from torchvision.io import read_image\n",
        "import torchvision.transforms.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torchvision.ops import masks_to_boxes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d4p3JCclCre"
      },
      "source": [
        "## Unzip/extract 'masks.zip' and 'images.zip' (uploaded as 2 separate zip files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RATQMJchpr5i"
      },
      "outputs": [],
      "source": [
        "# path where images and masks zip folders are located \n",
        "root = '/content/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1xynQURQiNh"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile(root +'masks.zip' , 'r') as zip_ref:\n",
        "  zip_ref.extractall(root)\n",
        "with zipfile.ZipFile(root + 'images.zip' , 'r') as zip_ref:\n",
        "  zip_ref.extractall(root)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VE9IhbXK2N-"
      },
      "source": [
        "## Notes/TODO:\n",
        "\n",
        "### may need to try resizing via padding only to avoid adding additional \"tampering\" or artifacts\n",
        "### can also use larger squares as input to YOLO\n",
        "### more DB and augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mlr80WBCzIsm"
      },
      "source": [
        "## Create Labeled Train/Val/Test Sets in Proper File Structure (from Masks for specific IF DB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSC2wpJcmCO4"
      },
      "outputs": [],
      "source": [
        "# YOLO requires images to be squares \n",
        "# choose appropriate side length\n",
        "im_size = 416\n",
        "# COVERAGE is a very small DB\n",
        "val_size = test_size = 15\n",
        "DB = 'coverage'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LpEY5UMPyu4"
      },
      "outputs": [],
      "source": [
        "# create file structures:\n",
        "# train \n",
        "os.mkdir(root + 'train')\n",
        "os.mkdir(root + 'train/' + 'labels')\n",
        "os.mkdir(root + 'train/' + 'images')\n",
        "# test\n",
        "os.mkdir(root + 'test')\n",
        "os.mkdir(root + 'test/' + 'labels')\n",
        "os.mkdir(root + 'test/' + 'images')\n",
        "# valid\n",
        "os.mkdir(root + 'valid')\n",
        "os.mkdir(root + 'valid/' + 'labels')\n",
        "os.mkdir(root + 'valid/' + 'images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Uz5G2E4Ivi1"
      },
      "outputs": [],
      "source": [
        "# image fraud DBs only include masks (no BBs) so this function extracts BBs\n",
        "# from masks to create the labels while placing ims and labels in proper YOLO\n",
        "# file structures (for each train/val/test set)\n",
        "\n",
        "def createLabeledSets(root, DB, test_size, val_size, im_size):\n",
        "\n",
        "\n",
        "  # to start add ims/labels to test subset (make sure ims not ordered in any way)\n",
        "  subset = 'test'\n",
        "  # get all mask names in a list\n",
        "  masks = list(os.listdir(os.path.join(root, 'masks')))\n",
        "\n",
        "  # iterate through each mask\n",
        "  for i in range(len(masks)):\n",
        "    if DB == 'coverage':\n",
        "      # remove forgery type info from image number so it matches with the corresponding image\n",
        "      # for COVERAGE dataset matching numbers in names mean corresponding image/mask pair\n",
        "      real_name = re.sub(\"[^0-9]\", \"\", masks[i])\n",
        "      name = real_name + 't'\n",
        "      # 'paste' image mask is the forged area (skip other masks)\n",
        "      if masks[i] != real_name + 'paste.jpeg':\n",
        "        continue\n",
        "      # COVERAGE contains a corresponding 'real' image for each tampered image\n",
        "      # write empty file meaning 'no object' for untampered images (ones without the 't' are untampered)\n",
        "      with open(os.path.join(root, subset, \"labels\", real_name + '.txt'), 'w') as f:     \n",
        "        f.write(' ')\n",
        "      # then add the real image to the set folder\n",
        "      im = cv2.imread(os.path.join(root, \"images\", real_name + '.jpeg'))\n",
        "      im = cv2.resize(im, (im_size,im_size))\n",
        "      cv2.imwrite(os.path.join(root, subset,\"images\", real_name + '.jpeg'), im)\n",
        "\n",
        "    # Pytorch reads image as tensor\n",
        "    mask = read_image(os.path.join(root, \"masks\", masks[i]))\n",
        "\n",
        "    # YOLO requires square images\n",
        "    transform = T.Resize((im_size,im_size))\n",
        "    mask = transform(mask)\n",
        "    mask = F.convert_image_dtype(mask, dtype=torch.float)\n",
        "    obj_ids = torch.unique(mask)\n",
        "    obj_ids = obj_ids[1:]\n",
        "    test = mask == obj_ids[:, None, None]\n",
        "    b = masks_to_boxes(test)\n",
        "\n",
        "    # YOLO requires coordinates in x,y center, x,y height/width\n",
        "    b_center_x = (b[0][0].item() + b[0][2].item()) / 2 \n",
        "    b_center_y = (b[0][1].item() + b[0][3].item()) / 2\n",
        "    b_width    = (b[0][2].item() - b[0][0].item())\n",
        "    b_height   = (b[0][3].item() - b[0][1].item())\n",
        "    # YOLO requires normalization of coordinates      \n",
        "    b_center_x /= im_size\n",
        "    b_center_y /= im_size \n",
        "    b_width    /= im_size \n",
        "    b_height   /= im_size\n",
        "    \n",
        "    if i <= val_size:\n",
        "      subset = 'valid'\n",
        "    elif test_size + val_size >= i > val_size:\n",
        "      subset = 'test' \n",
        "    else:\n",
        "      subset = 'train'\n",
        "    with open(os.path.join(root, subset, \"labels\", name + '.txt'), 'w') as f:\n",
        "      f.write(str(0) + ' ' + str(b_center_x) + ' ' + str(b_center_y) + ' ' + str(b_width) + ' ' + str(b_height))\n",
        "    # put actual tampered image into correct set \n",
        "    im = cv2.imread(os.path.join(root, \"images\", name + '.jpeg'))\n",
        "    im = cv2.resize(im, (im_size,im_size))\n",
        "    cv2.imwrite(os.path.join(root, subset,\"images\", name + '.jpeg'), im)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1K_EEAILPYr"
      },
      "outputs": [],
      "source": [
        "createLabeledSets(root, DB, test_size, val_size, im_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaFasW7jPun9",
        "outputId": "25988642-3c18-46f0-e8b7-f6f6b5047c2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/data.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/data.yaml\n",
        "train: /content/train/images\n",
        "val: /content/valid/images\n",
        "test: /content/test/images\n",
        "\n",
        "\n",
        "nc: 1\n",
        "names: ['tampered']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO copy weights from synthetic data trained model (add SyntheticImageFraudYOLO.ipynb code)"
      ],
      "metadata": {
        "id": "MSI0MynL3b_3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji2_KltGDrn8"
      },
      "source": [
        "##YOLOv5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9NTqXtqDrA1"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "!git reset --hard 886f1c03d839575afecb059accf74296fad395b6"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### had to change torch>= 1.7.0 to torch == 1.7.0 in requirements.txt (and reinstall above eg. https://github.com/ultralytics/yolov5/issues/8405) "
      ],
      "metadata": {
        "id": "D6ys5DmYTsQT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oNYVka2PVHu"
      },
      "outputs": [],
      "source": [
        "# install dependencies as necessary\n",
        "!pip install -qr requirements.txt  # install dependencies (ignore errors)\n",
        "import torch\n",
        "\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "from utils.google_utils import gdrive_download  # to download models/datasets\n",
        "\n",
        "# clear_output()\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzkgqryr06m5",
        "outputId": "7f699051-c6d8-41e2-9464-f16ab533f48c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/yolov5/models/custom_yolov5m.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/yolov5/models/custom_yolov5m.yaml\n",
        "\n",
        "# parameters\n",
        "nc: {num_classes}  # number of classes\n",
        "depth_multiple: 0.67  # model depth multiple\n",
        "width_multiple: 0.75  # layer channel multiple\n",
        "\n",
        "# anchors\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# YOLOv5 backbone\n",
        "backbone:\n",
        "  # [from, number, module, args]\n",
        "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
        "   [-1, 3, BottleneckCSP, [128]],\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
        "   [-1, 9, BottleneckCSP, [256]],\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
        "   [-1, 9, BottleneckCSP, [512]],\n",
        "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
        "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
        "  ]\n",
        "\n",
        "# YOLOv5 head\n",
        "head:\n",
        "  [[-1, 1, Conv, [512, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
        "\n",
        "   [-1, 1, Conv, [256, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
        "\n",
        "   [-1, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
        "\n",
        "   [-1, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
        "\n",
        "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
        "  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kHCFbw-QZi_"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "%cd /content/yolov5/\n",
        "!python train.py --img 416 --batch 16 --epochs 60 --data '/content/data.yaml' --cfg /content/yolov5/models/yolov5m.yaml --weights '' --name yolov5s_results  --cache"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python test.py --weights /content/yolov5/runs/train/yolov5s_results4/weights/best.pt --data /content/data.yaml --img 416 --conf 0.2 --task test --save-txt\n"
      ],
      "metadata": {
        "id": "uFjWUL5TU3OL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov5/\n",
        "!python detect.py --weights runs/train/yolov5s_results4/weights/best.pt --img 416 --conf 0.5 --source ../test/images"
      ],
      "metadata": {
        "id": "XHqf8SvUfAJH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "aNewImageFraudYOLO+DataPrep.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}