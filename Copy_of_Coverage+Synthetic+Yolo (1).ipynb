{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Coverage+Synthetic+Yolo",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Generalized code to prepare and combine (both synthetic and real) Image Fruad Datasets for use with YOLOv5"
      ],
      "metadata": {
        "id": "LXDcWoX-EICr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### imports"
      ],
      "metadata": {
        "id": "00Fx3qF7CwZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import re\n",
        "import yaml\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import glob\n",
        "from random import randint\n",
        "import os\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from torchvision.io import read_image\n",
        "import torchvision.transforms.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torchvision.ops import masks_to_boxes"
      ],
      "metadata": {
        "id": "wkxfF6C6UXS0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unzip/extract images and masks files (uploaded as zip files)"
      ],
      "metadata": {
        "id": "eFEiEBONUm0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# path whereimages and masks zip folder(s) are located \n",
        "root = '/content/'"
      ],
      "metadata": {
        "id": "VX1AI1Z-DMjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### COVERAGE"
      ],
      "metadata": {
        "id": "ZKpim5vBDUQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# coverage\n",
        "with zipfile.ZipFile(root +'masks.zip' , 'r') as zip_ref:\n",
        "  zip_ref.extractall(root)\n",
        "with zipfile.ZipFile(root + 'images.zip' , 'r') as zip_ref:\n",
        "  zip_ref.extractall(root)"
      ],
      "metadata": {
        "id": "0Jx-apZ4Uqmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mainly DB specific constants:\n",
        "# name of DB\n",
        "DB = 'coverage'\n",
        "# COVERAGE is a very small DB\n",
        "val_size = test_size = 15\n",
        "# name \n",
        "files = 'masks'"
      ],
      "metadata": {
        "id": "dNNloXvfB6vS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IEEE IFS-TC ImageForensics Challenge"
      ],
      "metadata": {
        "id": "-Dh1y1xHDV4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IEEE IFS-TC Image\n",
        "# Forensics Challenge\n",
        "with zipfile.ZipFile(root +'fake.zip' , 'r') as zip_ref:\n",
        "  zip_ref.extractall(root)"
      ],
      "metadata": {
        "id": "H-UQH4sz4ga9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### other constants"
      ],
      "metadata": {
        "id": "v5Cj8DulDdHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLO requires images to be squares \n",
        "# choose appropriate side length\n",
        "im_size = 416"
      ],
      "metadata": {
        "id": "IkQAZr8dCQLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and label synthetic Tampered Dataset (and divide into train/valid)\n",
        "- either save the weights (trained with synthetic data) to retrain or fine-tune with non-synthetic dataset or run add them to the same training set\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WEmATOhQUvbW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO:\n",
        "\n",
        "Datasets:\n",
        "- try other image fraud db\n",
        "- compare synthetic Pascal Voc images (download masks)\n",
        "- compare synthetic COCO images (download masks)\n",
        "\n",
        "Testing:\n",
        "- add in untampered images\n",
        "- add more augmented data from actual training set since there is a class imbalance\n",
        "\n",
        "Preprossing:\n",
        "- try resizing via padding only to avoid adding additional \"tampering\" or artifacts\n",
        "- move around masks pasted\n",
        "\n"
      ],
      "metadata": {
        "id": "cR1zChvkE-Qa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**root:** where directories with test/train/val will be created and where the original tampered/authentic images and masks will be unzipped\n",
        "**files:**"
      ],
      "metadata": {
        "id": "yctfXcRaM1Uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# image fraud DBs only include masks (no BBs) so this function extracts BBs\n",
        "# from masks to create the labels while placing properly formatted images and \n",
        "# labels in proper YOLO file structures (for each train/val/test set)\n",
        "# if synthetic = True then a synthetically crop object from another image and paste onto untampered image\n",
        "def createLabeledSets(root, DB, test_size, val_size, im_size, synthetic, percent_real = 0, augmentation = 'None', n_rotations = 1, bb_pad = 0):\n",
        "\n",
        "  # Create Labeled Train/Val/Test Sets in Proper File Structure\n",
        "  # train \n",
        "  os.mkdir(root + 'train')\n",
        "  os.mkdir(root + 'train/' + 'labels')\n",
        "  os.mkdir(root + 'train/' + 'images')\n",
        "  # test\n",
        "  os.mkdir(root + 'test')\n",
        "  os.mkdir(root + 'test/' + 'labels')\n",
        "  os.mkdir(root + 'test/' + 'images')\n",
        "  # valid\n",
        "  os.mkdir(root + 'valid')\n",
        "  os.mkdir(root + 'valid/' + 'labels')\n",
        "  os.mkdir(root + 'valid/' + 'images')\n",
        "  # get all mask names in a list (sorted so first images will always be in test set)\n",
        "  all_files = list(sorted(os.listdir(os.path.join(root, files))))\n",
        "  # get all images in a list \n",
        "  #images = list(sorted(os.listdir(os.path.join(root, 'images'))))\n",
        "  subset = 'test'\n",
        "    \n",
        "  # iterate through each mask \n",
        "  for i in range(len(all_files)):\n",
        "\n",
        "    if test_size <= i < (test_size + val_size):\n",
        "      subset = 'valid' #switch this with test\n",
        "    elif i >= (test_size + val_size):\n",
        "      subset = 'train'\n",
        "\n",
        "    if DB == 'coverage':\n",
        "      # remove forgery type info from image number so it matches with the corresponding image\n",
        "      # for COVERAGE dataset matching numbers in names mean corresponding image/mask pair\n",
        "      auth_name = re.sub(\"[^0-9]\", \"\", all_files[i])\n",
        "      tamp_name = auth_name + 't'\n",
        "\n",
        "      if all_files[i] != auth_name + 'paste.jpeg':\n",
        "        continue\n",
        "\n",
        "      # COVERAGE contains a corresponding 'real' image for each tampered image\n",
        "      # write empty file meaning 'no object' for untampered images (ones without the 't' are untampered)\n",
        "      with open(os.path.join(root, subset, \"labels\", auth_name + '.txt'), 'w') as f:     \n",
        "        f.write(' ')\n",
        "      # then add the real image to the set folder\n",
        "      im = cv2.imread(os.path.join(root, \"images\", auth_name + '.jpeg'))\n",
        "      im = cv2.resize(im, (im_size,im_size))\n",
        "      cv2.imwrite(os.path.join(root, subset,\"images\", auth_name + '.jpeg'), im)\n",
        "    \n",
        "    if DB == 'ifs-tc':\n",
        "      \n",
        "\n",
        "    for j in range(n_rotations):\n",
        "      # read in image to extract masked region\n",
        "      im = cv2.imread(os.path.join(root, \"images\", tamp_name + '.jpeg'))\n",
        "      # read corresponding mask\n",
        "      mask = cv2.imread(os.path.join(root, \"masks\", masks[i]))\n",
        "\n",
        "      # rotate both the mask and the tamped image its extracted from \n",
        "      if j == 0:\n",
        "        # no rotation (full 360)\n",
        "        mask = cv2.rotate(mask, cv2.ROTATE_180)\n",
        "        im = cv2.rotate(im, cv2.ROTATE_180)\n",
        "        rotate = cv2.ROTATE_180\n",
        "      elif j == 1:\n",
        "        if subset == 'test':\n",
        "          break\n",
        "        rotate = cv2.ROTATE_90_COUNTERCLOCKWISE\n",
        "      elif j == 2:\n",
        "        rotate = cv2.ROTATE_180\n",
        "      else:\n",
        "        rotate = cv2.ROTATE_90_CLOCKWISE\n",
        "      \n",
        "      # get BBs from mask\n",
        "      # first rotate and resize\n",
        "      mask = cv2.rotate(mask, rotate)\n",
        "\n",
        "      ### here\n",
        "      mask = cv2.resize(mask, (im_size,im_size))\n",
        "      # make sure image is binary and threshold\n",
        "      gray = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "      thresh = cv2.threshold(gray,250,255,cv2.THRESH_BINARY)[1]\n",
        "      cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "      cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
        "      for c in cnts:\n",
        "        x,y,w1,h1 = cv2.boundingRect(c)\n",
        "\n",
        "        \n",
        "      # YOLO requires coordinates in x,y center, x,y height/width\n",
        "      c_x = x + (w1 // 2) \n",
        "      c_y = y + (h1 // 2)\n",
        "      # YOLO requires normalization of coordinates      \n",
        "      c_x /= im_size\n",
        "      c_y /= im_size \n",
        "      w = (w1 + bb_pad) / im_size \n",
        "      h = (h1 + bb_pad)/ im_size\n",
        "      \n",
        "      # rotate and resize image (same ask mask)\n",
        "      im_r = cv2.rotate(im, rotate)\n",
        "\n",
        "      ### here\n",
        "      im = cv2.resize(im_r, (im_size,im_size))\n",
        "\n",
        "      if synthetic == True:  \n",
        "        # read in random image to paste extracted masked region onto it\n",
        "        # and keep BG and FG images in same sets:\n",
        "        if i < test_size:\n",
        "          num = randint(0,test_size)\n",
        "        else:\n",
        "          num = randint(test_size,len(images)-1)\n",
        "\n",
        "        # make sure to not paste on tampered image\n",
        "        im2_name = re.sub(\"[^0-9]\", \"\", masks[num])\n",
        "        im2 = cv2.imread(os.path.join(root, \"images\", im2_name + \".jpeg\")) \n",
        "\n",
        "        ### here\n",
        "        im2 = cv2.resize(im2, (im_size, im_size))\n",
        "      \n",
        "        # mask of im is 0/black everywhere where im2 will go   \n",
        "        im = np.where(mask == 0, im2, im) # also works\n",
        "        #im = np.where(mask >= 250, im, im2)\n",
        "\n",
        "      if augmentation != 'None':\n",
        "        # imagaug and albumentations (augmentations for BB included)\n",
        "        if subset == 'test':\n",
        "          break\n",
        "        if augmentation == 'brightness':\n",
        "          b = np.ones(im.shape, dtype='uint8')*70\n",
        "          im = cv2.add(im,b)\n",
        "\n",
        "        elif augmentation == 'dullness':\n",
        "          d = np.ones(im.shape, dtype='uint8')*70\n",
        "          im = cv2.subtract(im,d)\n",
        "\n",
        "        elif augmentation == 'sharpness':\n",
        "          s = np.array([[-1,-1,-1],[-1,10,-1],[-1,-1,-1]])\n",
        "          im = cv2.filter2D(im, -1,s)\n",
        "\n",
        "      # debug:\n",
        "      #im = cv2.rectangle(im, (x- (bb_pad//2),y- (bb_pad//2)), (x+w1 + (bb_pad//2),y+h1+ (bb_pad//2)), (255, 255, 255), 2)\n",
        "      \n",
        "      cv2.imwrite(os.path.join(root, subset, \"images\", tamp_name + '_' + augmentation + str(j) + '.jpeg'), im)\n",
        "\n",
        "      with open(os.path.join(root, subset, \"labels\", tamp_name + '_' + augmentation + str(j) + '.txt'), 'w') as f:\n",
        "        f.write(str(0) + ' ' + str(c_x) + ' ' + str(c_y) + ' ' + str(w) + ' ' + str(h))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7tsvQms1UyDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Label actual Tampered Dataset (and divide into test/train/valid)"
      ],
      "metadata": {
        "id": "GOdsGY5HU4cE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "createLabeledSets(root, files, DB, test_size, val_size, im_size, True, 0,   'None', 4)"
      ],
      "metadata": {
        "id": "Nrgt9LhNUxf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create sets (non-synthetic)"
      ],
      "metadata": {
        "id": "iVJJdlQ2YUai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "createLabeledSets(root, files, DB, test_size, val_size, im_size, False, 0, 'None', 4)"
      ],
      "metadata": {
        "id": "jdnmB7DCb2y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "createLabeledSets(root, files, DB, test_size, val_size, im_size, False, 0, 'brightness', 1)"
      ],
      "metadata": {
        "id": "_Ih5LzxiljJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "createLabeledSets(root, files, DB, test_size, val_size, im_size, False, 0, 'dullness', 1)"
      ],
      "metadata": {
        "id": "Av2lIOnNlqIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/data.yaml\n",
        "train: /content/train/images\n",
        "val: /content/valid/images\n",
        "test: /content/test/images\n",
        "\n",
        "\n",
        "nc: 1\n",
        "names: ['tampered']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cQAETqIVDZN",
        "outputId": "38d37b4c-c2ab-4b1a-86d6-97301bd35a35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### move images and masks folders into syn directory before running below"
      ],
      "metadata": {
        "id": "dQo85moCTxdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root = '/content/syn/'"
      ],
      "metadata": {
        "id": "m7-yu_hhVkrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create file structures:\n",
        "os.mkdir(root)\n",
        "# train \n",
        "os.mkdir(root + 'train')\n",
        "os.mkdir(root + 'train/' + 'labels')\n",
        "os.mkdir(root + 'train/' + 'images')\n",
        "# test\n",
        "os.mkdir(root + 'test')\n",
        "os.mkdir(root + 'test/' + 'labels')\n",
        "os.mkdir(root + 'test/' + 'images')\n",
        "# valid\n",
        "os.mkdir(root + 'valid')\n",
        "os.mkdir(root + 'valid/' + 'labels')\n",
        "os.mkdir(root + 'valid/' + 'images')"
      ],
      "metadata": {
        "id": "3PjTwoT-S65j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "createLabeledSets(root, DB, test_size, val_size, im_size, True, 'None', 2)"
      ],
      "metadata": {
        "id": "ug9knO1O9Cp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/data_syn.yaml\n",
        "train: /content/syn/train/images\n",
        "val: /content/syn/valid/images\n",
        "test: /content/syn/test/images\n",
        "\n",
        "\n",
        "nc: 1\n",
        "names: ['tampered']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSd51Qe477j1",
        "outputId": "1f9a368c-5426-42b4-9e7f-b282c9c21ce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/data_syn.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Clone repo, install dependencies and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80653543-bcba-40c5-d86f-08454f81e251"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "#import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:yolov5:YOLOv5 🚀 v6.1-386-g2e57b84 Python-3.7.13 torch-1.12.1+cu113 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n",
            "YOLOv5 🚀 v6.1-386-g2e57b84 Python-3.7.13 torch-1.12.1+cu113 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete ✅ (4 CPUs, 25.5 GB RAM, 37.6/166.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%cd /content/yolov5/\n",
        "!python train.py --img 416 --batch 16 --epochs 240 --data '/content/data.yaml' --cfg /content/yolov5/models/yolov5m.yaml --weights '/content/syn240.pt' --name yolov5s_results  --cache"
      ],
      "metadata": {
        "id": "S5e4zFticKEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%cd /content/yolov5/\n",
        "!python val.py --weights /content/yolov5/runs/train/yolov5s_results3/weights/best.pt --data /content/data.yaml --img 416 --conf 0.2 --task test --save-txt\n"
      ],
      "metadata": {
        "id": "vrE2RPn4jPf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov5/\n",
        "!python detect.py --weights runs/train/yolov5s_results/weights/best.pt --img 416 --conf 0.2 --source ../test/images"
      ],
      "metadata": {
        "id": "OPYFCKzek6Cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Freeze backbone"
      ],
      "metadata": {
        "id": "-v_ye08udHeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%cd /content/yolov5/\n",
        "!python train.py --freeze 10 --img 416 --batch 16 --epochs 240 --data '/content/data.yaml' --cfg /content/yolov5/models/yolov5m.yaml --weights '/content/syn240.pt' --name yolov5s_results  --cache"
      ],
      "metadata": {
        "id": "PdmCRg3bVh5e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}